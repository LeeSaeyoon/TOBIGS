{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "twitter = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('frozen1_preprocess.csv', encoding='cp949')\n",
    "data2 = pd.read_csv('frozen2_preprocess.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>수많은 세월동안 축적된 디즈니의 정수를 보여준 영화  겨울왕국의 성공은 디즈니와 함...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>프로즌 한 장 이요</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>아    너무 감동적이라 눈물이 핑 하다가도 올라프때문에 키 하면서 웃게되네요</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>영상미      재미      노래      캐릭터     스토리     스토리가 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>그래    전문 성우를쓰라니까   아이돌이나 유행어남발하는개그맨  어줍지않는배우써서...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  score\n",
       "0  수많은 세월동안 축적된 디즈니의 정수를 보여준 영화  겨울왕국의 성공은 디즈니와 함...     10\n",
       "1                                      프로즌 한 장 이요        10\n",
       "2        아    너무 감동적이라 눈물이 핑 하다가도 올라프때문에 키 하면서 웃게되네요     10\n",
       "3  영상미      재미      노래      캐릭터     스토리     스토리가 ...      9\n",
       "4  그래    전문 성우를쓰라니까   아이돌이나 유행어남발하는개그맨  어줍지않는배우써서...     10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>아기 안나가 너무 귀여워서 시작하자마자 울뻔했습니다</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>완벽한 결말입니다  안나 똑똑하고 솔직당당한거에 비해 주목을 못받는게 안타까웠었는데...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>노래가 넘 좋았어요마지막에 엘사 넘 예뻐용</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>편보다는 조금 아쉽지만 엘사가  곡이나 불러줘서 좋았어요 노래보다는 아 아 아 아...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>영상미에 놀라고 크리스토프때문에 웃다가 목소리 때문에 안타까움을  할아버지에게서 인...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  score\n",
       "0                    아기 안나가 너무 귀여워서 시작하자마자 울뻔했습니다        10\n",
       "1  완벽한 결말입니다  안나 똑똑하고 솔직당당한거에 비해 주목을 못받는게 안타까웠었는데...     10\n",
       "2                         노래가 넘 좋았어요마지막에 엘사 넘 예뻐용        10\n",
       "3   편보다는 조금 아쉽지만 엘사가  곡이나 불러줘서 좋았어요 노래보다는 아 아 아 아...      9\n",
       "4  영상미에 놀라고 크리스토프때문에 웃다가 목소리 때문에 안타까움을  할아버지에게서 인...      9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 겨울왕국1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag1 = []\n",
    "for i in data1['review']:\n",
    "    morph1 = twitter.pos(i)\n",
    "    word_tag1.append(morph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사 추출을 통한 리뷰 파악\n",
    "adj_list1 = []\n",
    "for i in word_tag1:\n",
    "    for word, tag in i:\n",
    "        if tag == 'Noun':\n",
    "            adj_list1.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('영화', 95), ('노래', 59), ('디즈니', 58), ('스토리', 47), ('정말', 38), ('엘사', 36), ('애니메이션', 34), ('최고', 34), ('진짜', 30), ('생각', 25), ('것', 24), ('사랑', 24), ('말', 24), ('점', 23), ('감동', 21), ('애니', 21), ('사람', 21), ('때', 21), ('애', 20), ('더', 20), ('이', 18), ('처음', 18), ('캐릭터', 17), ('보고', 17), ('겨울왕국', 16), ('번', 16), ('라푼젤', 15), ('영상', 15), ('더빙', 14), ('렛잇고', 14)]\n"
     ]
    }
   ],
   "source": [
    "# 명사의 빈도수 계산 & 상위 빈도 10위 까지 출력\n",
    "from collections import Counter\n",
    "counts1 = Counter(adj_list1)\n",
    "print(counts1.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 겨울왕국2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag2 = []\n",
    "for i in data2['review']:\n",
    "    morph2 = twitter.pos(i)\n",
    "    word_tag2.append(morph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형용사 추출을 통한 리뷰 파악\n",
    "adj_list2 = []\n",
    "for i in word_tag2:\n",
    "    for word, tag in i:\n",
    "        if tag == 'Noun':\n",
    "            adj_list2.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('엘사', 127), ('겨울왕국', 62), ('편', 60), ('안나', 59), ('노래', 48), ('스토리', 47), ('때', 43), ('올라프', 42), ('것', 37), ('감동', 36), ('영화', 35), ('더', 28), ('도', 24), ('크리스토프', 20), ('아이', 20), ('정말', 19), ('진짜', 19), ('저', 18), ('생각', 17), ('장면', 17), ('보고', 17), ('영상', 17), ('느낌', 16), ('정령', 16), ('또', 15), ('최고', 15), ('사랑', 14), ('번', 14), ('이', 13), ('상미', 12)]\n"
     ]
    }
   ],
   "source": [
    "# 형용사의 빈도수 계산 & 상위 빈도 10위 까지 출력\n",
    "from collections import Counter\n",
    "counts2 = Counter(adj_list2)\n",
    "print(counts2.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.586666666666667, 9.28888888888889)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['score'].mean(), data2['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.28888888888889"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_low = data1.loc[data1['score'] <= 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_high = data1.loc[data1['score'] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_low = data2.loc[data2['score'] <= 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_high = data2.loc[data2['score'] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 225\n",
      "15 255\n"
     ]
    }
   ],
   "source": [
    "print(len(data1_low), len(data1_high))\n",
    "print(len(data2_low), len(data2_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('영화', 25), ('스토리', 25), ('노래', 24), ('점', 15), ('디즈니', 13), ('렛잇고', 8), ('평점', 8), ('라푼젤', 7), ('정도', 7), ('캐릭터', 6)]\n"
     ]
    }
   ],
   "source": [
    "word_tag1 = []\n",
    "for i in data1_low['review']:\n",
    "    morph1 = twitter.pos(i)\n",
    "    word_tag1.append(morph1)\n",
    "    \n",
    "# 명사 추출을 통한 리뷰 파악\n",
    "adj_list1 = []\n",
    "for i in word_tag1:\n",
    "    for word, tag in i:\n",
    "        if tag == 'Noun':\n",
    "            adj_list1.append(word)\n",
    "            \n",
    "# 명사의 빈도수 계산 & 상위 빈도 10위 까지 출력\n",
    "from collections import Counter\n",
    "counts1 = Counter(adj_list1)\n",
    "print(counts1.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('영화', 70), ('디즈니', 45), ('노래', 35), ('정말', 35), ('엘사', 35), ('애니메이션', 33), ('최고', 32), ('진짜', 26), ('사랑', 23), ('스토리', 22)]\n"
     ]
    }
   ],
   "source": [
    "word_tag1 = []\n",
    "for i in data1_high['review']:\n",
    "    morph1 = twitter.pos(i)\n",
    "    word_tag1.append(morph1)\n",
    "    \n",
    "# 명사 추출을 통한 리뷰 파악\n",
    "noun_list1 = []\n",
    "for i in word_tag1:\n",
    "    for word, tag in i:\n",
    "        if tag == 'Noun':\n",
    "            noun_list1.append(word)\n",
    "            \n",
    "# 명사의 빈도수 계산 & 상위 빈도 10위 까지 출력\n",
    "from collections import Counter\n",
    "counts1 = Counter(noun_list1)\n",
    "print(counts1.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('영화', 70), ('디즈니', 45), ('노래', 35), ('정말', 35), ('엘사', 35), ('애니메이션', 33), ('최고', 32), ('진짜', 26), ('사랑', 23), ('스토리', 22)]\n"
     ]
    }
   ],
   "source": [
    "word_tag2 = []\n",
    "for i in data2_low['review']:\n",
    "    morph2 = twitter.pos(i)\n",
    "    word_tag2.append(morph2)\n",
    "    \n",
    "# 명사 추출을 통한 리뷰 파악\n",
    "noun_list2 = []\n",
    "for i in word_tag1:\n",
    "    for word, tag in i:\n",
    "        if tag == 'Noun':\n",
    "            noun_list2.append(word)\n",
    "            \n",
    "# 명사의 빈도수 계산 & 상위 빈도 10위 까지 출력\n",
    "from collections import Counter\n",
    "counts2 = Counter(noun_list2)\n",
    "print(counts2.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('영화', 70), ('디즈니', 45), ('노래', 35), ('정말', 35), ('엘사', 35), ('애니메이션', 33), ('최고', 32), ('진짜', 26), ('사랑', 23), ('스토리', 22)]\n"
     ]
    }
   ],
   "source": [
    "word_tag2 = []\n",
    "for i in data2_high['review']:\n",
    "    morph2 = twitter.pos(i)\n",
    "    word_tag2.append(morph2)\n",
    "    \n",
    "# 명사 추출을 통한 리뷰 파악\n",
    "noun_list2 = []\n",
    "for i in word_tag1:\n",
    "    for word, tag in i:\n",
    "        if tag == 'Noun':\n",
    "            noun_list2.append(word)\n",
    "            \n",
    "# 명사의 빈도수 계산 & 상위 빈도 10위 까지 출력\n",
    "from collections import Counter\n",
    "counts2 = Counter(noun_list2)\n",
    "print(counts2.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING\n",
    "def make_corpus(text, corpus):\n",
    "    for s in text.split('\\n'):\n",
    "        corpus.append(['/'.join(p) for p in twitter.pos(s)])\n",
    "    return corpus\n",
    "\n",
    "def make_corpus_rm_stopwords(text, corpus):\n",
    "    for s in text.split('\\n'):\n",
    "        corpus.append(['/'.join(p) for p in twitter.pos(s) if p[1] != \"Josa\"]) \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1_low = []\n",
    "for i in data1_low['review']:\n",
    "    # 토큰 모음집 만들기\n",
    "    # make_corpus(i, corpus1)\n",
    "    # 특수문자 제거\n",
    "    make_corpus_rm_stopwords(i, corpus1_low)\n",
    "    \n",
    "corpus1_high = []\n",
    "for i in data1_high['review']:\n",
    "    # 토큰 모음집 만들기\n",
    "    # make_corpus(i, corpus1)\n",
    "    # 특수문자 제거\n",
    "    make_corpus_rm_stopwords(i, corpus1_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2_low = []\n",
    "for i in data2_low['review']:\n",
    "    # 토큰 모음집 만들기\n",
    "    # make_corpus(i, corpus1)\n",
    "    # 특수문자 제거\n",
    "    make_corpus_rm_stopwords(i, corpus2_low)\n",
    "    \n",
    "corpus2_high = []\n",
    "for i in data2_high['review']:\n",
    "    # 토큰 모음집 만들기\n",
    "    # make_corpus(i, corpus1)\n",
    "    # 특수문자 제거\n",
    "    make_corpus_rm_stopwords(i, corpus2_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar with '엘사' \n",
      " [('성/Noun', 0.9984533786773682), ('무슨/Noun', 0.998444139957428), ('성/Suffix', 0.997733473777771), ('정신/Noun', 0.9964184761047363), ('중/Suffix', 0.9960681796073914), ('많이/Adverb', 0.9938435554504395), ('식/Suffix', 0.9924851655960083), ('관객/Noun', 0.9890703558921814), ('전개/Noun', 0.9884139895439148), ('디즈니/Noun', 0.9878299832344055)]\n"
     ]
    }
   ],
   "source": [
    "Fast_Text_Model = FastText(corpus1_low, size=3, window=2, min_count=2, workers=1, iter=1000, sg=0)\n",
    "print(\"Similar with '엘사' \\n\", Fast_Text_Model.wv.most_similar('최고/Noun', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('보여준/Verb', 0.9931619167327881),\n",
       " ('같습니다/Adjective', 0.989978015422821),\n",
       " ('좋았어요/Adjective', 0.989156186580658),\n",
       " ('멋지게/Adjective', 0.9877684116363525),\n",
       " ('있다/Adjective', 0.9875741600990295),\n",
       " ('사랑/Noun', 0.9858614802360535),\n",
       " ('뛰어난/Adjective', 0.9848148822784424),\n",
       " ('나머지/Noun', 0.9826844930648804),\n",
       " ('이야기/Noun', 0.9813811779022217),\n",
       " ('좀/Noun', 0.9812054634094238)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fast_Text_Model = FastText(corpus1_high, size=3, window=2, min_count=2, workers=1, iter=1000, sg=0)\n",
    "Fast_Text_Model.wv.most_similar('좋은/Adjective', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('네/Determiner', 0.999935507774353),\n",
       " ('여자친구/Noun', 0.999919056892395),\n",
       " ('그래픽/Noun', 0.9995104074478149),\n",
       " ('더빙/Noun', 0.9994431734085083),\n",
       " ('대/Verb', 0.9992256760597229),\n",
       " ('남/Noun', 0.9989943504333496),\n",
       " ('로/Noun', 0.9983292818069458),\n",
       " ('좋았습니다/Adjective', 0.9983160495758057),\n",
       " ('분/Noun', 0.997758686542511),\n",
       " ('번/Noun', 0.9971999526023865)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fast_Text_Model = FastText(corpus2_high, size=3, window=2, min_count=2, workers=1, iter=1000, sg=0)\n",
    "Fast_Text_Model.wv.most_similar('좋은/Adjective', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 깨지는 문제 대처\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=1213)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(Fast_Text_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
