{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Local Response Normarlization\n",
    "- Dropout (비율 0.5)\n",
    "- Stochastic Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            ## [Layer 1] Convolution \n",
    "            # Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
    "            \n",
    "            ## [Layer 2] Max Pooling \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            ## [Layer 3] Convolution \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
    "            \n",
    "            ## [Layer 4] Max Pooling\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            ## [Layer 5] Convolution\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            ## [Layer 6] Convolution\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            ## [Layer 7] Convolution\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            ## [Layer 8] Max Pooling\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            ## [Layer 9] Fully Connected Layer\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            ## [Layer 10] Fully Connected Layer\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            ## [Layer 11] Fully Connected Layer\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
      "              ReLU-2           [-1, 96, 55, 55]               0\n",
      " LocalResponseNorm-3           [-1, 96, 55, 55]               0\n",
      "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
      "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
      "              ReLU-6          [-1, 256, 27, 27]               0\n",
      " LocalResponseNorm-7          [-1, 256, 27, 27]               0\n",
      "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
      "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
      "             ReLU-10          [-1, 384, 13, 13]               0\n",
      "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-12          [-1, 384, 13, 13]               0\n",
      "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-14          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
      "          Dropout-16                 [-1, 9216]               0\n",
      "           Linear-17                 [-1, 4096]      37,752,832\n",
      "             ReLU-18                 [-1, 4096]               0\n",
      "          Dropout-19                 [-1, 4096]               0\n",
      "           Linear-20                 [-1, 4096]      16,781,312\n",
      "             ReLU-21                 [-1, 4096]               0\n",
      "           Linear-22                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 14.73\n",
      "Params size (MB): 237.95\n",
      "Estimated Total Size (MB): 253.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = AlexNet()\n",
    "## Model Summary\n",
    "summary(model, input_size=(3, 227, 227))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class LocalResponseNormalization(Layer):\n",
    "\n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape \n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1,1), padding=\"same\", pool_mode='avg')\n",
    "        summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        return x / denom \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (227, 227, 3)\n",
    "num_classes = 1000\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "## [Layer 1] Convolution \n",
    "model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=4, \n",
    "                           padding='same', input_shape=input_shape))\n",
    "    \n",
    "## [Layer 2] Max Pooling \n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2))\n",
    "    \n",
    "## [Layer 3] Convolution \n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=1,\n",
    "                           activation=\"relu\", padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "    \n",
    "## [Layer 4] Max Pooling \n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2))\n",
    "  \n",
    "## [Layer 5] Convolution\n",
    "model.add(tf.keras.layers.Conv2D(filters=384, kernel_size = (3,3), strides=1,\n",
    "                           activation=\"relu\", padding=\"same\"))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "    \n",
    "## [Layer 6] Convolution\n",
    "model.add(tf.keras.layers.Conv2D(filters=384, kernel_size = (3,3), strides=1,\n",
    "                           activation=\"relu\", padding=\"same\"))\n",
    "    \n",
    "## [Layer 7] Convolution\n",
    "model.add(tf.keras.layers.Conv2D(filters=256, kernel_size = (3,3), strides=1,\n",
    "                           activation=\"relu\", padding=\"same\"))\n",
    "    \n",
    "## [Layer 8] Max Pooling\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2))\n",
    "    \n",
    "## [Layer 9] Fully Connected Layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(4096, activation=\"relu\"))\n",
    "\n",
    "## [Layer 10] Fully Connected Layer\n",
    "model.add(tf.keras.layers.Dense(4096, activation=\"relu\"))\n",
    "\n",
    "## [Layer 11] Fully Connected Layer\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=0.01, decay=5e-5, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 57, 57, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MNIST Data에 적용해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:, :, :, np.newaxis].astype('float32') / 255.0\n",
    "X_test = X_test[:, :, :, np.newaxis].astype('float32') / 255.0\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28, 1), (10000, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시간이 오래걸리는 관계로 10000개의 데이터만 뽑기로!\n",
    "X_train = X_train[:10000]\n",
    "Y_train = Y_train[:10000]\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "## [Layer 1] Convolution \n",
    "m = tf.keras.models.Sequential()\n",
    "m.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, \n",
    "                           padding='same', input_shape=input_shape))\n",
    "\n",
    "## [Layer 2] Max Pooling \n",
    "m.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "## [Layer 3] Convolution \n",
    "m.add(tf.keras.layers.Conv2D(filters=192, kernel_size=(3,3), strides=1,\n",
    "                           activation=\"relu\", padding='same'))\n",
    "m.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "    \n",
    "## [Layer 4] Max Pooling \n",
    "m.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "  \n",
    "## [Layer 5] Convolution\n",
    "m.add(tf.keras.layers.Conv2D(filters=384, kernel_size = (3,3), strides=1,\n",
    "                           activation=\"relu\", padding=\"same\"))\n",
    "m.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "    \n",
    "## [Layer 6] Convolution\n",
    "m.add(tf.keras.layers.Conv2D(filters=256, kernel_size = (3,3), strides=1,\n",
    "                           activation=\"relu\", padding=\"same\"))\n",
    "    \n",
    "## [Layer 7] Convolution\n",
    "m.add(tf.keras.layers.Conv2D(filters=256, kernel_size = (3,3), strides=1,\n",
    "                           activation=\"relu\", padding=\"same\"))\n",
    "    \n",
    "## [Layer 8] Max Pooling\n",
    "m.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "## [Layer 9] Fully Connected Layer\n",
    "m.add(tf.keras.layers.Flatten())\n",
    "m.add(tf.keras.layers.Dense(4096, activation=\"relu\"))\n",
    "\n",
    "## [Layer 10] Fully Connected Layer\n",
    "m.add(tf.keras.layers.Dense(2048, activation=\"relu\"))\n",
    "\n",
    "## [Layer 11] Fully Connected Layer\n",
    "m.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=0.01, decay=5e-5, momentum=0.9)\n",
    "m.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 192)       110784    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 14, 14, 192)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 384)         663936    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 7, 7, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 256)         884992    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              9441280   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 20,102,858\n",
      "Trainable params: 20,102,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 - 294s - loss: 2.3010 - accuracy: 0.1328 - val_loss: 2.2981 - val_accuracy: 0.1736\n",
      "Epoch 2/10\n",
      "10000/10000 - 347s - loss: 2.2954 - accuracy: 0.1224 - val_loss: 2.2926 - val_accuracy: 0.1136\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = m.fit(X_train, Y_train, epochs=10, batch_size=600,\n",
    "                   validation_data=(X_test, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'], 'b-', label=\"training\")\n",
    "plt.plot(hist.history['val_accuracy'], 'r:', label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
