{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "- 중간 중간 assignment라고 되어있고 ''' ? ''' 이 있을거에요 그 부분을 채워주시면 됩니다 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 : Gaussian Naive Bayes Classification 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn에 Gaussian Naive Bayes Classification 클래스 함수가 이미 있습니다\n",
    "\n",
    "- 그것을 활용하여 간단하게 예측만 하시면 됩니다\n",
    "\n",
    "- 필요 함수 링크를 주석으로 처리하여 첨부했으니 보시고 사용해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn에 내장되어있는 붓꽃 데이터를 사용할 겁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 붓꽃데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 설명변수 x가 꽃받침 길이, 꽃받침 폭 , 꽃잎 길이 , 꽃잎 폭 임을 알 수 있습니다\n",
    "- sepal length , sepal width , petal length , petal width\n",
    "- 타겟변수 y는 붓꽃의 품종으로 총 3가지의 종류가 있는 걸 알 수 있습니다\n",
    "- Iris-Setosa , Iris-Versicolour , Iris-Virginica 가 0 1 2 로 분류되어 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris.data)\n",
    "y = pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 설명변수 x와 타겟변수 y를 판다스의 데이터프레임 형태로 만듭니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "145  2\n",
       "146  2\n",
       "147  2\n",
       "148  2\n",
       "149  2\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가우시안 나이브 베이즈 함수를 불러옵니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1) assignment\n",
    "- train set과 test set을 80 대 20의 비율로 나누어 주세요\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- 해당 함수를 사용하시고 사용 후에 주석으로 해당 함수에 어떤 인자들이 있는지 설명해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. data: \n",
    "    데이터는 lists, numpy arrays, matrices, pandas dataframes 등 다양한 형태를 포함합니다. \n",
    "    클래스 값을 포함하여 하나의 데이터로 받을 수도 있고 클래스 값을 분리해서 두개의 데이터로도 받을 수 있습니다.\n",
    "\n",
    "2. test_size: \n",
    "    float, int or None 값이 들어올 수 있으며 default는 None 입니다.\n",
    "    0에서 1의 값(float)을 입력하면 전체 데이터 셋에서 test set의 비율을 의미합니다. \n",
    "    0.3을 입력할 경우 전체 데이터의 30%를 랜덤하게 테스트로 사용합니다. \n",
    "    정수 값(int)을 입력하면 데이터 개수를 의미합니다. \n",
    "    None을 입력하고 훈련 데이터 셋 사이즈를 지정할 경우 훈련 데이터셋을 뺀 나머지를 테스트 데이터로 사용합니다. \n",
    "    기본 값은 0.25입니다.\n",
    "\n",
    "3. train_size:\n",
    "    마찬가지로 float, int or None 값이 들어올 수 있으며 defalut는 None 입니다.\n",
    "    값의 종류에 따라 나타나는 값의 의미는 test_size와 같습니다.\n",
    "    보통 test_size를 설정하고, train_size를 설정하지 않으면 test_size 이외의 모든 데이터를 train data로 설정합니다.\n",
    "    \n",
    "4. random_state:\n",
    "    int, RandomState instance or None 값이 들어올 수 있으며 defalut는 None입니다.\n",
    "    정수 값을 입력하면 숫자를 random하게 생성할때 사용되는 seed 숫자로 사용되며, \n",
    "    None을 입력하면 np.random에서 제공하는 random number generator가 사용됩니다.\n",
    "    하지만 매번 해당 코드를 돌릴 때마다 train, test data가 달라지는 것이 싫다면 random_state를 설정해주는 것이 좋습니다.\n",
    "\n",
    "5. shuffle:\n",
    "    boolean 값이 들어올 수 있으며 데이터를 split하기 전에 데이터를 섞을 것인지를 의미합니다.\n",
    "    default 값은 True 입니다.\n",
    "    \n",
    "6. stratify:\n",
    "    train, test data 들이 원래의 input dataset의 클래스의 비율과 같은 비율을 가지도록 할 것인지 지정합니다.\n",
    "    예를 들어 0, 1의 클래스가 input dataset에 20:80 비율로 있었다면 train, test data 역시 각각의 클래스가 같은 비율로 있도록 지정할 수 있습니다.\n",
    "    shuffle=False로 지정했다면 stratify 값은 None이어야 합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-2) assignment\n",
    "- 가우시안 나이브 베이즈 함수를 사용하여 학습을 시킨 후 score 값을 계산하여 주세요\n",
    "- 모두 GaussianNB 클래스 안에 메서드로 들어있습니다\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "- 해당 함수를 사용하시고 사용 후에 주석으로 해당 함수에 어떤 인자들이 있는지 설명해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*** GaussianNB() ***\n",
    "1. priors: \n",
    "    class들의 사전확률로 array 값이 들어올 수 있습니다.\n",
    "    주어지지 않으면 사전확률은 데이터에서 구해집니다.\n",
    "\n",
    "2. var_smoothing: \n",
    "    float 형태로 들어올 수 있으며, default 값은 1e-9 입니다.\n",
    "    안정성을 위해 모든 feature들 가운데 분산이 가장 큰 것의 일부를 더해줍니다.\n",
    "    \n",
    "*** methods ***\n",
    "- fit\n",
    "1. X:\n",
    "    행렬 형태로 들어오는 feature data 입니다.\n",
    "2. y:\n",
    "    행렬 형태로 들어오는 target data 입니다.\n",
    "3. same_weight:\n",
    "    각 sample들에 적용되는 weight이며 default는 None 입니다.\n",
    "    \n",
    "- predict\n",
    "1. X:\n",
    "    행렬 형태로 들어오는 feature data 입니다.\n",
    "    \n",
    "- score\n",
    "1. X:\n",
    "    Test feature data 입니다.\n",
    "2. y:\n",
    "    X의 True Labels 입니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 : Naive Bayes Classification 해보기\n",
    "- 제가 임의로 만든 데이터 셋입니다\n",
    "- spam 메세지에 gamble money hi라는 단어의 유무를 기준으로 0과 1을 주었고 spam 메세지인지 아닌지를 spam에 0과1로 정해주었습니다\n",
    "- 설명변수는 gamble, money, spam 이고 종속변수는 spam입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamble_spam = {'gamble' : [1,0,1,0,1,0,0,0,1,0,0,0,1,1,1,1,0,1,0,0,0,0,0,0,0,\n",
    "                           1,0,1,1,0,1,0,1,0,1,1,1,1,0,0,0,1,0,1,0,1,0,1,0,1,\n",
    "                           0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,1,1,0,1,1,1,1,1,0,0,\n",
    "                           1,0,0,1,0,0,0,1,1,0,1,0,1,1,0,0,0,1,0,1,1,1,0,1,1],\n",
    "               'money' : [1,1,1,0,1,0,0,0,1,0,0,0,1,0,1,1,0,1,1,0,1,1,1,1,1,\n",
    "                          0,0,0,1,1,1,0,0,0,1,1,0,0,0,1,0,1,1,0,1,0,0,1,0,1,\n",
    "                          1,0,1,1,0,1,0,1,0,1,1,0,0,0,1,1,0,0,0,1,1,1,1,1,1,\n",
    "                          1,1,0,1,0,1,1,0,0,1,0,1,1,1,1,0,0,1,0,0,1,0,0,1,0],\n",
    "               'hi' : [0,1,0,1,0,1,0,0,1,0,0,0,1,0,1,1,1,0,1,1,1,0,0,0,0,\n",
    "                       1,0,0,1,0,0,0,1,0,1,1,1,0,1,1,1,0,0,1,0,1,0,1,1,0,\n",
    "                       1,0,0,0,1,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,0,0,0,0,0,\n",
    "                       1,1,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,0,1,0,0,0,1,0,0],\n",
    "                'spam' : [1,0,1,0,1,0,0,0,1,0,0,0,1,1,1,1,0,1,1,0,0,0,1,1,0,\n",
    "                          1,0,1,1,0,0,1,1,0,0,0,0,1,1,0,1,0,0,1,0,1,0,1,0,1,\n",
    "                          0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,\n",
    "                          1,0,0,1,0,0,0,1,1,0,1,0,1,1,0,0,0,1,0,1,1,1,0,1,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 딕셔너리 데이터를 판다스 데이터 프레임으로 변경하여줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(gamble_spam, columns = ['gamble', 'money', 'hi', 'spam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1) assignment\n",
    "- 해당 판다스 데이터프레임 형식을 numpy array형식으로 변환해 주세요\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.as_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "spam_data = df.as_matrix() # <=> df.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2) assignment\n",
    "- P(spam=1), P(spam=0)\n",
    "- P(gamble=1|spam=1), P(money=1|spam=1), P(hi=1|spam=1)\n",
    "- P(gamble=1|spam=0), P(money=1|spam=0), P(hi=1|spam=0)\n",
    "- 위의 확률들을 구하여 주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 P(spam)의 확률 부터 구해주세요\n",
    "- P(spam=1)인 경우만 제가 완성을 해두었습니다 참고하시면 금방 금방 채우실거에요 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = sum(spam_data[:,3]==1)/len(spam_data) # P(spam=1)\n",
    "p_spam_not = sum(spam_data[:,3]==0)/len(spam_data) # P(spam=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gamble , money , hi의 조건부 확률을 다 구해주세요\n",
    "- P(gamble=0|spam=1) = 1 - P(gamble=1|spam=1) 의 형태로 구하면 되므로 굳이 따로 구하지 않습니다\n",
    "- 각 값이 어떤 조건부 확률인지 이름만으로는 알기 어려울거같아 바로 옆에 주석을 달아놨습니다 참고하세요\n",
    "- 위랑 마찮가지로 제일 위에 껀 제가 해놨어요 참고해서 한번 구해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gamble_spam = sum((spam_data[:, 0] == 1) & (spam_data[:, 3] == 1)) / sum(spam_data[:, 3] == 1) # P(gamble=1|spam=1)\n",
    "p_gamble_spam_not = sum((spam_data[:, 0] == 1) & (spam_data[:, 3] == 0)) / sum(spam_data[:, 3] == 0) # P(gamble=1|spam=0)\n",
    "\n",
    "p_money_spam = sum((spam_data[:, 1] == 1) & (spam_data[:, 3] == 1)) / sum(spam_data[:, 3] == 1) # P(money=1|spam=1)\n",
    "p_money_spam_not = sum((spam_data[:, 1] == 1) & (spam_data[:, 3] == 0)) / sum(spam_data[:, 3] == 0) # P(money=1|spam=0)\n",
    "\n",
    "p_hi_spam = sum((spam_data[:, 2] == 1) & (spam_data[:, 3] == 1)) / sum(spam_data[:, 3] == 1) # P(hi=1|spam=1)\n",
    "p_hi_spam_not = sum((spam_data[:, 2] == 1) & (spam_data[:, 3] == 0)) / sum(spam_data[:, 3] == 0) # P(hi=1|spam=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 P(*|spam=1)값 리스트와 P(*|spam=0)값 리스트를 생성해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = [p_gamble_spam,p_money_spam,p_hi_spam]\n",
    "proba_not = [p_gamble_spam_not,p_money_spam_not,p_hi_spam_not]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 요건 테스트 셋이에요\n",
    "- 예를 들어 [0,1,0]인 경우 gamble=0,money=1,hi=0인 경우에 spam인지 아닌지 확률을 계산해 달라는 의미 입니다\n",
    "- 설명변수가 3개 밖에 안되기때문에 [0,0,0] ~ [1,1,1] 8가지 모든 경우에 대해 확률 P(*|spam=1)를 구할 거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [[i,j,k] for i in range(2) for j in range(2) for k in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 1, 1],\n",
       " [1, 0, 0],\n",
       " [1, 0, 1],\n",
       " [1, 1, 0],\n",
       " [1, 1, 1]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3) assignment\n",
    "- 조건부 확률을 구하는 함수를 구해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x는 해당 독립변수가 0인지 1인지를 받는 인자이구요\n",
    "- p는 해당 독립변수가 1일때의 조건부 확률이 들어갑니다\n",
    "- P(X=x|Y=1) = x*P(X=1|Y=1)+(1-x)*P(X=0|Y=1)을 응용하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_proba(x,p):\n",
    "    return x*p + (1-x)*(1-p) # x * P(X=1|Y=1) + (1-x) * (1 - P(X=1|Y=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test경우에 대해 각 확률을 반환해주는 함수를 생성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(p_spam,p_spam_not,test,proba,proba_not):\n",
    "    result = []\n",
    "    for i in range(8):\n",
    "        a = p_spam\n",
    "        b = p_spam_not\n",
    "        for j in range(3):\n",
    "            a = a*con_proba(test[i][j], proba[j])\n",
    "            b = b*con_proba(test[i][j], proba_not[j])\n",
    "        summation = a+b\n",
    "        result.append([a/summation,b/summation])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과 입니다 다음과 같은 값들이 똑같이 나오면 과제 성공이에요\n",
    "- 왼쪽이 spam 메세지일 확률, 오른쪽이 spam 메세지가 아닐 확률입니다\n",
    "- gamble money hi라는 단어가 들어가면 들어갈수록 spam메세지인걸 알수가 있네요\n",
    "- spam 메세지일 확률이 0.5를 넘기는 아래에서 6,7,8행의 경우가 spam 메세지로 분류가 되겠네요\n",
    "- 즉 gamble이라는 단어와 money 혹은 hi라는 단어가 하나라도 같이 있으면 spam메세지가 되나봐요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.12561158047604412, 0.8743884195239557],\n",
       " [0.1274444080172175, 0.8725555919827824],\n",
       " [0.13153830892959942, 0.8684616910704006],\n",
       " [0.1334444168893966, 0.8665555831106035],\n",
       " [0.7542408952456084, 0.24575910475439156],\n",
       " [0.757301978407486, 0.24269802159251405],\n",
       " [0.7639150506833852, 0.23608494931661472],\n",
       " [0.7668928774284339, 0.233107122571566]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process(p_spam,p_spam_not,test,proba,proba_not)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
