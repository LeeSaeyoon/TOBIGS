{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2\n",
    "### - Anomaly detection 데이터셋을 SVM을 이용해서 판별해보자\n",
    "### - 데이터 분포 : True : 0.17프로 나머지 다 False, Row약 28만행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Anomaly detection(사기감지 데이터) 로드\n",
    "df = pd.read_csv('anomaly-detection/creditcard.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284806, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Class'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.2f%%',shadow=True, labels =['0','1']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 매우 Imbalance한 데이터임을 알 수 있다.\n",
    "- Class 1(True) 인 경우가 0.17%로 매우 적다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. minority class를 oversampling하여 imbalance의 문제를 해결해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤하게 20000개의 데이터를 뽑았다.\n",
    "np.random.seed(0)\n",
    "rndperm = np.random.permutation(df.shape[0])\n",
    "df1=df.loc[rndperm[:20000],:]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19959\n",
       "1       41\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.iloc[:, :-1]\n",
    "y = df1.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "not_fraud = train[train.Class==0]\n",
    "fraud = train[train.Class==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- minority class를 oversampling하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14966\n",
       "0    14966\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check new class counts\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = upsampled.Class\n",
    "X_train = upsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9862\n",
      "Confusion Matrix: \n",
      "[[4925   68]\n",
      " [   1    6]]\n",
      "\n",
      "Precision:  0.08108108108108109\n",
      "Recall:  0.8571428571428571\n",
      "f1 Score:  0.14814814814814817\n"
     ]
    }
   ],
   "source": [
    "#default linear\n",
    "svc=SVC(kernel='linear') \n",
    "svc.fit(X_train,y_train) \n",
    "y_pred=svc.predict(X_test) \n",
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"f1 Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9954\n",
      "Confusion Matrix: \n",
      "[[4973   20]\n",
      " [   3    4]]\n",
      "\n",
      "Precision:  0.16666666666666666\n",
      "Recall:  0.5714285714285714\n",
      "f1 Score:  0.25806451612903225\n"
     ]
    }
   ],
   "source": [
    "#default RBF kernel\n",
    "svc2=SVC(kernel='rbf')\n",
    "svc2.fit(X_train,y_train)\n",
    "y_pred2=svc2.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred2))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test, y_pred2))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred2))\n",
    "print(\"f1 Score: \", f1_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range=list(np.arange(1,80,1))\n",
    "acc_score = []\n",
    "\n",
    "for c in tqdm(C_range):\n",
    "    svc = SVC(kernel='linear', gamma='auto', C=c)\n",
    "    svc.fit(X_train,y_train)\n",
    "    scores = cross_validate(svc, X, y, cv=5, scoring='accuracy') # 점수를 리스트로 관리해줍니다.\n",
    "    score = np.mean(scores['test_score']) #5개 스코어 값의 평균\n",
    "    acc_score.append(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(acc_score)) #제일 좋은 결과\n",
    "print(C_range[np.argmax(acc_score)]) #제일 좋은 결과가 나온 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range=list(np.arange(1,80,1))\n",
    "plt.plot(C_range,acc_score)\n",
    "plt.xticks(np.arange(0,100,5))\n",
    "plt.xlabel('Value of C for SVC')\n",
    "plt.ylabel('Cross-Validated Accuracy Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.987\n",
      "Confusion Matrix: \n",
      "[[4930   63]\n",
      " [   2    5]]\n",
      "\n",
      "Precision:  0.07352941176470588\n",
      "Recall:  0.7142857142857143\n",
      "f1 Score:  0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "svm_over = SVC(kernel = 'linear', gamma = 3, C = 20)\n",
    "svm_over.fit(X_train,y_train)\n",
    "y_pred=svm_over.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "print(\"f1 Score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy는 매우 높지만 f1 score가 0에 가까워 매우 안좋은 결과임을 알 수 있다.\n",
    "- 하지만 Recall이 1인 것으로 보아 사기인 경우는 모두 분류해냈음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. majority class를 undersampling하여 imbalance의 문제를 해결해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.iloc[:, :-1]\n",
    "y2 = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X2, y2, random_state=1213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213604, 30), (71202, 30))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.shape, X_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = pd.concat([X_train_2, y_train_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "not_fraud = train_2[train_2.Class==0]\n",
    "fraud = train_2[train_2.Class==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- majority class를 undersampling하여 imbalance의 문제를 해결해보기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample majority\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    359\n",
       "0    359\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking counts\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = downsampled.Class\n",
    "X_train_2 = downsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_2 = pd.DataFrame(scaler.fit_transform(X_train_2), columns = X_train_2.columns)\n",
    "X_test_2 = pd.DataFrame(scaler.transform(X_test_2), columns = X_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9691862588129547\n",
      "Confusion Matrix: \n",
      "[[68885  2184]\n",
      " [   10   123]]\n",
      "\n",
      "Precision:  0.053315994798439535\n",
      "Recall:  0.924812030075188\n",
      "f1 Score:  0.10081967213114754\n"
     ]
    }
   ],
   "source": [
    "#default linear\n",
    "svc=SVC(kernel='linear') \n",
    "svc.fit(X_train_2,y_train_2) \n",
    "y_pred=svc.predict(X_test_2) \n",
    "print(\"Accuracy: \", accuracy_score(y_test_2,y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test_2, y_pred))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test_2, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test_2, y_pred))\n",
    "print(\"f1 Score: \", f1_score(y_test_2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9748883458329822\n",
      "Confusion Matrix: \n",
      "[[69293  1776]\n",
      " [   12   121]]\n",
      "\n",
      "Precision:  0.06378492356352135\n",
      "Recall:  0.9097744360902256\n",
      "f1 Score:  0.11921182266009853\n"
     ]
    }
   ],
   "source": [
    "#default RBF kernel\n",
    "svc2=SVC(kernel='rbf')\n",
    "svc2.fit(X_train_2,y_train_2)\n",
    "y_pred2=svc2.predict(X_test_2)\n",
    "print(\"Accuracy: \", accuracy_score(y_test_2,y_pred2))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test_2, y_pred2))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test_2, y_pred2))\n",
    "print(\"Recall: \", recall_score(y_test_2, y_pred2))\n",
    "print(\"f1 Score: \", f1_score(y_test_2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gamma 값을 0.01로 tuning하여 결과를 확인해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9691862588129547\n",
      "Confusion Matrix: \n",
      "[[68885  2184]\n",
      " [   10   123]]\n",
      "\n",
      "Precision:  0.053315994798439535\n",
      "Recall:  0.924812030075188\n",
      "f1 Score:  0.10081967213114754\n"
     ]
    }
   ],
   "source": [
    "svm_under = SVC(kernel = 'linear', gamma = 0.01, C = 1)\n",
    "svm_under.fit(X_train_2,y_train_2)\n",
    "y_pred=svm_under.predict(X_test_2)\n",
    "print(\"Accuracy: \", accuracy_score(y_test_2,y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test_2, y_pred))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test_2, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test_2, y_pred_under))\n",
    "print(\"f1 Score: \", f1_score(y_test_2, y_pred_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9878514648464931\n",
      "Confusion Matrix: \n",
      "[[70218   851]\n",
      " [   14   119]]\n",
      "\n",
      "Precision:  0.12268041237113401\n",
      "Recall:  0.8947368421052632\n",
      "f1 Score:  0.2157751586582049\n"
     ]
    }
   ],
   "source": [
    "svm_under = SVC(kernel = 'rbf', gamma = 0.01, C = 1)\n",
    "svm_under.fit(X_train_2,y_train_2)\n",
    "y_pred=svm_under.predict(X_test_2)\n",
    "print(\"Accuracy: \", accuracy_score(y_test_2,y_pred))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test_2, y_pred))\n",
    "print()\n",
    "print(\"Precision: \", precision_score(y_test_2, y_pred))\n",
    "print(\"Recall: \", recall_score(y_test_2, y_pred))\n",
    "print(\"f1 Score: \", f1_score(y_test_2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
