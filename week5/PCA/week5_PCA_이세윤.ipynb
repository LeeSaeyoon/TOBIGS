{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반갑습니다 13기 여러분\n",
    "\n",
    "과제를 진행해 볼게요\n",
    "\n",
    "혹시라도 도저히 모르겠거나 해결이 안되신다면 01040493041로 전화주시거나 카톡주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ''' ? ''' 이 있는 부분을 채워주시면 됩니다\n",
    "\n",
    "나는 내 스타일로 하겠다 하시면 그냥 구현 하셔도 됩니다!!\n",
    "\n",
    "참고하셔야 하는 함수들은 링크 달아드렸으니 들어가서 확인해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) PCA의 과정을 한번 차근차근 밟아 볼거에요 잘 따라 오세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#   기본 모듈들을 불러와 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [95, 91, 66, 94, 68, 63, 12, 73, 93, 51, 13, 70, 63, 63, 97, 56, 67, 96, 75, 6]\n",
    "x2 = [56, 27, 25, 1, 9, 80, 92, 69, 6, 25, 83, 82, 54, 97, 66, 93, 76, 59, 94, 9]\n",
    "x3 = [57, 34, 9, 79, 4, 77, 100, 42, 6, 96, 61, 66, 9, 25, 84, 46, 16, 63, 53, 30]\n",
    "\n",
    "#   설명변수 x1, x2, x3의 값이 이렇게 있네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1,x2,x3),axis=0)\n",
    "\n",
    "#   설명변수들을 하나의 행렬로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.T,columns=['x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2   x3\n",
       "0   95  56   57\n",
       "1   91  27   34\n",
       "2   66  25    9\n",
       "3   94   1   79\n",
       "4   68   9    4\n",
       "5   63  80   77\n",
       "6   12  92  100\n",
       "7   73  69   42\n",
       "8   93   6    6\n",
       "9   51  25   96\n",
       "10  13  83   61\n",
       "11  70  82   66\n",
       "12  63  54    9\n",
       "13  63  97   25\n",
       "14  97  66   84\n",
       "15  56  93   46\n",
       "16  67  76   16\n",
       "17  96  59   63\n",
       "18  75  94   53\n",
       "19   6   9   30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1) 먼저 PCA를 시작하기 전에 항상!!!!!! 데이터를 scaling 해주어야 해요\n",
    "\n",
    "https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/ 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.02614175,  0.30684189],\n",
       "       [ 0.93801686, -0.86575334, -0.46445467],\n",
       "       [ 0.01477192, -0.92726334, -1.30282049],\n",
       "       [ 1.04880625, -1.66538341,  1.04460382],\n",
       "       [ 0.08863151, -1.41934339, -1.47049366],\n",
       "       [-0.09601747,  0.76426183,  0.97753455],\n",
       "       [-1.97943714,  1.13332186,  1.74883111],\n",
       "       [ 0.2732805 ,  0.42595679, -0.1961776 ],\n",
       "       [ 1.01187645, -1.5116084 , -1.40342439],\n",
       "       [-0.53917504, -0.92726334,  1.61469258],\n",
       "       [-1.94250735,  0.85652683,  0.44098042],\n",
       "       [ 0.16249111,  0.82577183,  0.60865359],\n",
       "       [-0.09601747, -0.03536825, -1.30282049],\n",
       "       [-0.09601747,  1.28709688, -0.76626636],\n",
       "       [ 1.15959564,  0.33369178,  1.21227698],\n",
       "       [-0.35452606,  1.16407687, -0.06203907],\n",
       "       [ 0.05170172,  0.64124181, -1.06807806],\n",
       "       [ 1.12266584,  0.11840676,  0.50804969],\n",
       "       [ 0.3471401 ,  1.19483187,  0.17270336],\n",
       "       [-2.20101593, -1.41934339, -0.5985932 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_std.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.93801686,  0.01477192,  1.04880625,  0.08863151,\n",
       "        -0.09601747, -1.97943714,  0.2732805 ,  1.01187645, -0.53917504,\n",
       "        -1.94250735,  0.16249111, -0.09601747, -0.09601747,  1.15959564,\n",
       "        -0.35452606,  0.05170172,  1.12266584,  0.3471401 , -2.20101593],\n",
       "       [ 0.02614175, -0.86575334, -0.92726334, -1.66538341, -1.41934339,\n",
       "         0.76426183,  1.13332186,  0.42595679, -1.5116084 , -0.92726334,\n",
       "         0.85652683,  0.82577183, -0.03536825,  1.28709688,  0.33369178,\n",
       "         1.16407687,  0.64124181,  0.11840676,  1.19483187, -1.41934339],\n",
       "       [ 0.30684189, -0.46445467, -1.30282049,  1.04460382, -1.47049366,\n",
       "         0.97753455,  1.74883111, -0.1961776 , -1.40342439,  1.61469258,\n",
       "         0.44098042,  0.60865359, -1.30282049, -0.76626636,  1.21227698,\n",
       "        -0.06203907, -1.06807806,  0.50804969,  0.17270336, -0.5985932 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2) 자 그럼 공분산 행렬을 구해볼게요\\\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3) 이제 고유값과 고유벡터를 구해볼게요\n",
    "\n",
    "방법은 실습코드에 있어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = lin.eig(cov_matrix)[0]\n",
    "eigenvectors = lin.eig(cov_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48756162 0.94435407 0.72597904]\n",
      "[[ 0.47018528 -0.85137353 -0.23257022]\n",
      " [-0.64960236 -0.15545725 -0.74421087]\n",
      " [-0.59744671 -0.50099516  0.62614797]]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[0][0] = eigenvalues[0]\n",
    "mat[1][1] = eigenvalues[1]\n",
    "mat[2][2] = eigenvalues[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48756162, 0.        , 0.        ],\n",
       "       [0.        , 0.94435407, 0.        ],\n",
       "       [0.        , 0.        , 0.72597904]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4) 자 이제 고유값 분해를 할 모든 준비가 되었어요 고유값 분해의 곱으로 원래 공분산 행렬을 구해보세요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html 를 참고해서 행렬 끼리 곱하시면 됩니다\n",
    "\n",
    "행렬 곱으로 eigenvector x mat x eigenvector.T 하면 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(eigenvectors,mat),eigenvectors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5) 마지막으로 고유 벡터 축으로 값을 변환해 볼게요\n",
    "\n",
    "함수로 한번 정의해 보았어요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_coordinates(X,eigenvectors):\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        if i == 0:\n",
    "            new = [X.dot(eigenvectors.T[i])]\n",
    "        else:\n",
    "            new = np.concatenate((new, [X.dot(eigenvectors.T[i])]),axis=0)\n",
    "    return new.T\n",
    "\n",
    "# 모든 고유 벡터 축으로 데이터를 projection한 값입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates(X_std,eigenvectors)\n",
    "\n",
    "# 새로운 축으로 변환되어 나타난 데이터들입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PCA를 구현해 보세요\n",
    "\n",
    "위의 과정을 이해하셨다면 충분히 하실 수 있을거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MYPCA(X,number):\n",
    "    scaler = StandardScaler()\n",
    "    x_std = scaler.fit_transform(X)\n",
    "    features = x_std.T\n",
    "    cov_matrix = np.cov(features)\n",
    "    \n",
    "    eigenvalues = lin.eig(cov_matrix)[0]\n",
    "    eigenvectors = lin.eig(cov_matrix)[1]\n",
    "    \n",
    "    new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    new_coordinate = new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    index = eigenvalues.argsort()\n",
    "    index = list(index)\n",
    "    \n",
    "    for i in range(number):\n",
    "        if i==0:\n",
    "            new = [new_coordinate[:,index.index(i)]]\n",
    "        else:\n",
    "            new = np.concatenate(([new_coordinate[:,index.index(i)]],new),axis=0)\n",
    "    return new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)\n",
    "\n",
    "# 새로운 축으로 잘 변환되어서 나타나나요?\n",
    "# 위에서 했던 PCA랑은 차이가 있을 수 있어요 왜냐하면 위에서는 고유값이 큰 축 순서로 정렬을 안했었거든요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) sklearn이랑 비교를 해볼까요?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31019368, -1.08215716, -0.07983642],\n",
       "       [-1.28092404, -0.43132556,  0.13533091],\n",
       "       [-1.38766381,  0.78428014, -0.12911446],\n",
       "       [-0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [-1.84222365,  0.88189889,  0.11493111],\n",
       "       [ 1.12563709, -0.52680338,  0.06564012],\n",
       "       [ 2.71174416,  0.63290138,  0.71195473],\n",
       "       [ 0.03100441, -0.20059783, -0.50339479],\n",
       "       [-2.29618509,  0.07661447,  0.01087174],\n",
       "       [ 0.61585248, -0.205764  ,  1.82651199],\n",
       "       [ 1.73320252,  1.29971699,  0.09045178],\n",
       "       [ 0.82366049, -0.57164535, -0.27123176],\n",
       "       [-0.75619512,  0.73995175, -0.76710616],\n",
       "       [ 0.42344386,  0.26555394, -1.41533681],\n",
       "       [ 0.39581307, -1.64646874,  0.24104031],\n",
       "       [ 0.88581498,  0.15195119, -0.82271209],\n",
       "       [-0.24587691,  0.39139878, -1.15801831],\n",
       "       [-0.14741103, -1.22874561, -0.03110396],\n",
       "       [ 0.7161265 , -0.56781471, -0.86180345],\n",
       "       [-0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)\n",
    "# sklearn과 동일한 값이 나왔다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) MNIST data에 적용을 해볼게요!\n",
    "\n",
    "mnist data를 따로 내려받지 않게 압축파일에 같이 두었어요~!!!\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_mldata # fetch_openml\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# mnist 손글씨 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "\n",
    "# 7만개의 작은 숫자 이미지\n",
    "# 행 열이 반대로 되어있음 -> 전치\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "69995       0  ...         0         0         0         0         0   \n",
       "69996       0  ...         0         0         0         0         0   \n",
       "69997       0  ...         0         0         0         0         0   \n",
       "69998       0  ...         0         0         0         0         0   \n",
       "69999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783    y  \n",
       "0             0         0         0         0  0.0  \n",
       "1             0         0         0         0  0.0  \n",
       "2             0         0         0         0  0.0  \n",
       "3             0         0         0         0  0.0  \n",
       "4             0         0         0         0  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "69995         0         0         0         0  9.0  \n",
       "69996         0         0         0         0  9.0  \n",
       "69997         0         0         0         0  9.0  \n",
       "69998         0         0         0         0  9.0  \n",
       "69999         0         0         0         0  9.0  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 여러 머신러닝 기법들이 있을거에요\n",
    "\n",
    "4-1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주시고요\n",
    "\n",
    "4-2) PCA를 이용하여 mnist data를 축소해서 학습을 해주세요 / test error가 제일 작으신 분께 상품을 드리겠습니다 ^0^\n",
    "\n",
    "특정한 틀 없이 자유롭게 하시면 됩니다!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "\n",
    "# 3가지 model을 사용해서 비교해보자\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1) Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split을 통해 데이터를 0.8 : 0.2의 비율로 분할\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56000, 784), (56000,), (14000, 784), (14000,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>56000.000000</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>56000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177179</td>\n",
       "      <td>0.098071</td>\n",
       "      <td>0.044286</td>\n",
       "      <td>0.016536</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.587082</td>\n",
       "      <td>4.252553</td>\n",
       "      <td>2.689853</td>\n",
       "      <td>1.566497</td>\n",
       "      <td>1.233971</td>\n",
       "      <td>0.245095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
       "count  56000.0  56000.0  56000.0  56000.0  56000.0  56000.0  56000.0  56000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel8   pixel9  ...      pixel774      pixel775      pixel776  \\\n",
       "count  56000.0  56000.0  ...  56000.000000  56000.000000  56000.000000   \n",
       "mean       0.0      0.0  ...      0.177179      0.098071      0.044286   \n",
       "std        0.0      0.0  ...      5.587082      4.252553      2.689853   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
       "\n",
       "           pixel777      pixel778      pixel779  pixel780  pixel781  pixel782  \\\n",
       "count  56000.000000  56000.000000  56000.000000   56000.0   56000.0   56000.0   \n",
       "mean       0.016536      0.008696      0.001036       0.0       0.0       0.0   \n",
       "std        1.566497      1.233971      0.245095       0.0       0.0       0.0   \n",
       "min        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "25%        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "50%        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "75%        0.000000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "max      253.000000    254.000000     58.000000       0.0       0.0       0.0   \n",
       "\n",
       "       pixel783  \n",
       "count   56000.0  \n",
       "mean        0.0  \n",
       "std         0.0  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.0  \n",
       "75%         0.0  \n",
       "max         0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()\n",
    "# 보면 0밖에 없는 값들도 있지만 최대값이 254인 컬럼도 존재하는 것으로 보아\n",
    "# scaling이 필요해보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Normalization \n",
    "X_train_norm = X_train.astype('float32')\n",
    "X_test_norm = X_test.astype('float32')\n",
    "\n",
    "X_train_norm /= 255\n",
    "X_test_norm /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 가지 방법으로 나온 데이터를 각각 학습시켜 비교해보기로 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2) PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca를 이용해서 누적된 분산의 비율이 80%가 되는 주성분 축을 선택해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled\n",
    "pca = PCA(n_components=0.8, whiten=True).fit(X_train_std)\n",
    "\"\"\"\n",
    "### WHITENING ###\n",
    "이미지를 이용하여 알고리즘을 훈련시킬 때 입력되는 데이터는 어느정도 redundant를 가지게 된다.\n",
    "이미지에서 인접한 픽셀들은 서로 높게 관련되어 있을 것이기 때문이다.\n",
    "인접한 픽셀들간의 관련성이 있기 때문에 PCA는 입력 데이터를 더 낮은 차원의 것으로 아주 적은 에러로 근사할 수 있도록 해준다.\n",
    "\"\"\"\n",
    "\n",
    "X_train_pca = pca.transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 feature가 설명하는 분산\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized\n",
    "pca2 = PCA(n_components=0.8, whiten=True).fit(X_train_norm)\n",
    "\"\"\"\n",
    "### WHITENING ###\n",
    "이미지를 이용하여 알고리즘을 훈련시킬 때\n",
    "입력되는 데이터는 어느정도 redundant를 가지게 된다.\n",
    "이미지에서 인접한 픽셀들은 서로 높게 관련되어 있을 것이기 때문이다.\n",
    "인접한 픽셀들간의 관련성이 있기 때문에 \n",
    "PCA는 입력 데이터를 더 낮은 차원의 것으로 아주 적은 에러로 근사할 수 있도록 해준다.\n",
    "\"\"\"\n",
    "\n",
    "X_train_pca2 = pca2.transform(X_train_norm)\n",
    "X_test_pca2 = pca2.transform(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 feature가 설명하는 분산의 비율\n",
    "features = range(pca2.n_components_)\n",
    "plt.bar(features, pca2.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2718.724s\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "t0 = time()\n",
    "svc = SVC(C=0.1, kernel='rbf', gamma=0.1)\n",
    "svc = svc.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.46819642857142857\n",
      "Test Accuracy:  0.38971428571428574\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", svc.score(X_train_pca, y_train))\n",
    "print(\"Test Accuracy: \", svc.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 648.006s\n"
     ]
    }
   ],
   "source": [
    "# Normalized\n",
    "t0 = time()\n",
    "svc = SVC(C=0.1, kernel='rbf', gamma=0.1)\n",
    "svc = svc.fit(X_train_pca2, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.867875\n",
      "Test Accuracy:  0.8175\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", svc.score(X_train_pca2, y_train))\n",
    "print(\"Test Accuracy: \", svc.score(X_test_pca2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순히 255로 나누어 0에서 1사이의 값으로 만들어준 경우(Normalized)에 Accuracy가 훨씬 높았다.\n",
    "- Normalized 데이터를 학습하는데 걸리는 시간 또한 더 빨랐다.\n",
    "- 따라서 normalized 데이터를 이용해서 parameter를 tuning해주는 방향으로 진행해보기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 711.982s\n"
     ]
    }
   ],
   "source": [
    "# C=2 & Gamma=0.1\n",
    "t0 = time()\n",
    "svc = SVC(C=2, kernel='rbf', gamma=0.1)\n",
    "svc = svc.fit(X_train_pca2, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9999821428571428\n",
      "Test Accuracy:  0.9712142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", svc.score(X_train_pca2, y_train))\n",
    "print(\"Test Accuracy: \", svc.score(X_test_pca2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 31.850s\n"
     ]
    }
   ],
   "source": [
    "# C=2 & Gamma=0.01\n",
    "t0 = time()\n",
    "svc2 = SVC(C=2, kernel='rbf', gamma=0.01)\n",
    "svc2 = svc2.fit(X_train_pca2, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9878214285714285\n",
      "Test Accuracy:  0.9796428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", svc2.score(X_train_pca2, y_train))\n",
    "print(\"Test Accuracy: \", svc2.score(X_test_pca2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1321,    0,   14,    2,    0,    0,    3,    0,    7,    2],\n",
       "       [   0, 1554,   14,    3,    2,    1,    1,    1,    4,    1],\n",
       "       [   1,    1, 1387,    2,    1,    0,    0,    2,    6,    0],\n",
       "       [   0,    0,   14, 1392,    0,   10,    0,    3,   14,    1],\n",
       "       [   0,    1,   11,    0, 1295,    0,    0,    1,   12,    8],\n",
       "       [   2,    0,   12,   10,    1, 1240,    2,    0,   18,    1],\n",
       "       [   4,    1,   28,    0,    2,    7, 1354,    0,   11,    0],\n",
       "       [   1,    3,   30,    1,    2,    1,    0, 1422,   10,    6],\n",
       "       [   0,    5,    8,    4,    1,    8,    0,    1, 1363,    1],\n",
       "       [   0,    1,   22,   13,    6,    8,    0,    2,   27, 1269]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test_pca2)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1335,    0,    1,    1,    0,    1,    5,    1,    2,    3],\n",
       "       [   0, 1569,    5,    1,    1,    0,    0,    3,    1,    1],\n",
       "       [   5,    5, 1372,    1,    2,    0,    3,    7,    5,    0],\n",
       "       [   2,    0,    7, 1397,    0,   16,    0,    6,    5,    1],\n",
       "       [   2,    1,    0,    1, 1307,    0,    1,    3,    1,   12],\n",
       "       [   3,    3,    1,   16,    1, 1244,    6,    1,    7,    4],\n",
       "       [   5,    1,    4,    0,    2,    1, 1391,    0,    3,    0],\n",
       "       [   2,    6,    8,    1,    3,    0,    0, 1446,    1,    9],\n",
       "       [   1,    8,    6,    6,    2,    8,    0,    2, 1352,    6],\n",
       "       [   1,    2,    2,   11,   15,    2,    0,    7,    6, 1302]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = svc2.predict(X_test_pca2)\n",
    "confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM에서 가장 높은 경우의 Test Accuracy는 **0.9796428571428571**이 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.724s\n"
     ]
    }
   ],
   "source": [
    "# Scaled\n",
    "t0 = time()\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9468928571428571\n",
      "Test Accuracy:  0.9371428571428572\n",
      "done in 1483.124s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print(\"Train Accuracy: \", knn.score(X_train_pca, y_train))\n",
    "print(\"Test Accuracy: \", knn.score(X_test_pca, y_test))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.264s\n"
     ]
    }
   ],
   "source": [
    "# Normalized\n",
    "t0 = time()\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_pca2, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9727321428571428\n",
      "Test Accuracy:  0.964\n",
      "done in 561.405s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print(\"Train Accuracy: \", knn.score(X_train_pca2, y_train))\n",
    "print(\"Test Accuracy: \", knn.score(X_test_pca2, y_test))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순히 255로 나누어 0에서 1사이의 값으로 만들어준 경우(Normalized)에 Accuracy가 훨씬 높았다.\n",
    "- 따라서 normalized 데이터를 이용해서 parameter를 tuning해주는 방향으로 진행해보기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.225s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(X_train_pca2, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9798214285714286\n",
      "Test Accuracy:  0.9672142857142857\n",
      "done in 566.715s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print(\"Train Accuracy: \", knn2.score(X_train_pca2, y_train))\n",
    "print(\"Test Accuracy: \", knn2.score(X_test_pca2, y_test))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scaling하지 않은 경우도 보자\n",
    "- pca의 차원을 50으로 진행해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.504s\n",
      "Train Accuracy:  0.9844285714285714\n",
      "Test Accuracy:  0.9777857142857143\n",
      "\n",
      "done in 281.645s\n"
     ]
    }
   ],
   "source": [
    "pca_k = PCA(n_components=50)\n",
    "X_train_pcak = pca_k.fit_transform(X_train)\n",
    "X_test_pcak = pca_k.transform(X_test)\n",
    "\n",
    "t0 = time()\n",
    "knn3 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn3.fit(X_train_pcak, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "print(\"Train Accuracy: \", knn3.score(X_train_pcak, y_train))\n",
    "print(\"Test Accuracy: \", knn3.score(X_test_pcak, y_test))\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN에서 가장 높은 경우의 Test Accuracy는 **0.9777857142857143**이 나왔다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
