{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안녕하세요 투빅스 보충 과제입니다 :)\n",
    "\n",
    "안녕하세요 투빅스 12기 김태한입니다 :)\n",
    "\n",
    "이번 과제는 코로나 바이러스로 예상치 못한 휴식시간이 생겨 여러분의 딥러닝 감을 유지하고자 드리게 되었습니다.  \n",
    "\n",
    "투빅이분들이라면 분명 쉽게 해낼거라 믿습니다!!\n",
    "\n",
    "\n",
    "모르시는 거 있으시면 저 그리고 12기 멘토분들을 많이 많이 괴롭혀주세요!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분들은 저번 과제로 뉴럴넷 구현을 이미 한번 하셨습니다!  \n",
    "\n",
    "사실 이번 과제의 최종 목적도 뉴럴넷 구현인데요 이미 한번 하셨고 실력들이 워낙 출중하셔서 금방금방 하실수 있으실거에요.  \n",
    "\n",
    "구현에 바로 들어가기에 앞서 전체 네트워크 구조와 각 구성요소의 행렬 차원 및 오차역전파(back propagation) 복습이 1번 과제입니다.  \n",
    "\n",
    "**?** 에 들어갈 수식을 채워주시면 됩니다!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Shape 정리\n",
    "\n",
    "n : sample_data 수  \n",
    "d : input_dimension  \n",
    "h : hidden_layer_dimension  \n",
    "c : output_dimension  \n",
    "\n",
    "X : input_data  \n",
    "W1 : layer1_weight  \n",
    "b1 : layer1_bias  \n",
    "H : X*W1+b1\n",
    "A : activation function 거친 value\n",
    "W2 : layer2_weight  \n",
    "b2 : layer2_bias  \n",
    "S : A*W2+b2  \n",
    "P : softmax 거친 value  \n",
    "\n",
    "**X==(n,d)  \n",
    "W1==(d,h) 채워주세요  \n",
    "b1==(h,)  \n",
    "H==(n,h) 채워주세요  \n",
    "A==(n,h)  \n",
    "W2==(h,c)  \n",
    "b2==(c,) 채워주세요  \n",
    "S==(n,c) 채워주세요  \n",
    "P==(n,c)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix 미분 정리\n",
    "$H = XW+b　　　(n,h) = (n,d)\\times(d,h)+(h,)$  \n",
    "$L = f(H)$  \n",
    "$\\frac{\\partial L}{\\partial W} = \\frac{\\partial H}{\\partial W} \\times \\frac{\\partial L}{\\partial H} = X^T\\frac{\\partial L}{\\partial H}$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial H} \\times \\frac{\\partial H}{\\partial X} = \\frac{\\partial L}{\\partial H}W^T$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial b} = 1*\\frac{\\partial L}{\\partial H}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Layers Chain Rule 정리\n",
    "**Forward** \n",
    "\n",
    "$H = XW_{1} + b$  \n",
    "$A = ReLU(H)$  \n",
    "$S = AW_{2} + b_{2}$  \n",
    "$P = Softmax(S)$  \n",
    "$L = -LogLikelihood(P)$\n",
    "\n",
    "\n",
    "**Backward**\n",
    "\n",
    "$\\frac{\\partial L}{\\partial S} = P-T$　:　T는 Label  \n",
    "$\\frac{\\partial L}{\\partial W_{2}} = \\frac{\\partial S}{\\partial W_{2}}\\frac{\\partial L}{\\partial S} = A^T(P-T)$ 　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial b_{2}} = 1*\\frac{\\partial L}{\\partial S} = P-T$  \n",
    "$\\frac{\\partial L}{\\partial A} = \\frac{\\partial L}{\\partial S}\\frac{\\partial S}{\\partial A} = (P-T)W^T_2$　채워주세요  \n",
    "$\\frac{\\partial L}{\\partial H} = \\frac{\\partial A}{\\partial H}\\frac{\\partial L}{\\partial A}$  \n",
    "$\\frac{\\partial L}{\\partial W_{1}} = \\frac{\\partial H}{\\partial W_{1}}\\frac{\\partial L}{\\partial H} = X^{T}\\frac{\\partial L}{\\partial H}$  \n",
    "$\\frac{\\partial L}{\\partial b_{1}} = \\frac{\\partial L}{\\partial H}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같이 드린 파일중 model.py라는 파일이 있을거에요!!!  \n",
    "그 친구의 빈칸을 채워주시면 되겠습니다~!!  \n",
    "model.py의 함수는 assignment3의 모델 만들기에서 사용되니 참고하시면서 채워주시면 도움이 될거에요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 저희가 구현한 모델을 가지고 한번 cifar-10 dataset을 학습해볼게요!!  \n",
    "근데 시작하기에 앞서 pip install keras 를 해주세요!!  \n",
    "\n",
    "3번과제의 목적은 하이퍼파라미터를 튜닝하던 다른방법을 사용하던 해서 마지막에 그림그리기에서 높은 validation accuracy가 나오도록 하는 과제입니다!!  \n",
    "\n",
    "모델을 2층이아니라 본인만의 3층으로 발전시켜도 좋구요 다른 여러가지 방법들이 있겠죠!?!?!?  \n",
    "\n",
    "가장 높은 validation accuracy를 뽑으신 분께 상품을 드리겠습니다아~!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 load\n",
    "\n",
    "keras 프레임워크를 이용하여 데이터를 로드해 옵니다.  \n",
    "32*32*3차원의 데이터를 3072차원으로 바꾸는 것 까지 해드릴게요.\n",
    "필요하면 sklearn.preprocessing의 scaler를 사용해보셔도 좋습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Model import TwoLayerNet\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"cifar10-data/x_train_data.npy\")\n",
    "y_train = np.load(\"cifar10-data/y_train_data.npy\")\n",
    "x_test = np.load(\"cifar10-data/x_test_data.npy\")\n",
    "y_test = np.load(\"cifar10-data/y_test_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3072)\n",
      "(1000, 3072)\n",
      "(5000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확인\n",
    "\n",
    "실제 데이터가 어떻게 생겼는지 한번 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -71.71074,  -74.05614,  -69.5538 , ...,   -3.63908,  -33.8503 ,\n",
       "         -42.38186],\n",
       "       [  23.28926,   40.94386,   54.4462 , ...,   16.36092,    7.1497 ,\n",
       "          29.61814],\n",
       "       [ 124.28926,  118.94386,  122.4462 , ...,  -46.63908,  -39.8503 ,\n",
       "         -30.38186],\n",
       "       ...,\n",
       "       [  36.28926,   26.94386,   12.4462 , ...,  -84.63908,  -47.8503 ,\n",
       "         -30.38186],\n",
       "       [  23.28926,   15.94386,   -7.5538 , ...,   67.36092,  121.1497 ,\n",
       "          -0.38186],\n",
       "       [ -85.71074, -104.05614, -111.5538 , ...,   29.36092,   16.1497 ,\n",
       "         -14.38186]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  27.28926,  -24.05614,  -83.5538 , ..., -105.63908,  -58.8503 ,\n",
       "          -4.38186],\n",
       "       [ 104.28926,   98.94386,  102.4462 , ...,   59.36092,   74.1497 ,\n",
       "          84.61814],\n",
       "       [  27.28926,   53.94386,   89.4462 , ..., -119.63908, -117.8503 ,\n",
       "        -107.38186],\n",
       "       ...,\n",
       "       [ -27.71074,  -12.05614,  -31.5538 , ...,  -59.63908,  -83.8503 ,\n",
       "         -77.38186],\n",
       "       [ -53.71074,  -22.05614,  -99.5538 , ...,  -91.63908,  -81.8503 ,\n",
       "         -84.38186],\n",
       "       [  44.28926,   43.94386,   41.4462 , ...,  -33.63908,  -15.8503 ,\n",
       "          16.61814]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model2 import ThreeLayerNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size1 = 500\n",
    "hidden_size2 = 50\n",
    "output_size = 10\n",
    "epoch_size = 2000\n",
    "batch_size = 200\n",
    "learning_rate = 1e-5\n",
    "N = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = np.random.choice(N, batch_size) #이번 배치에서 쓸 데이터들 인덱스 추출\n",
    "x_batch = x_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ThreeLayerNet(x_batch, input_size=input_size, hidden_size1=hidden_size1, hidden_size2=hidden_size2, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 test accuracy : 0.102\n",
      "0 test loss     : 2.63984507683994\n",
      "10 test accuracy : 0.107\n",
      "10 test loss     : 2.3034576147034014\n",
      "20 test accuracy : 0.109\n",
      "20 test loss     : 2.2982523097920686\n",
      "30 test accuracy : 0.109\n",
      "30 test loss     : 2.294639443836634\n",
      "40 test accuracy : 0.121\n",
      "40 test loss     : 2.292789289734112\n",
      "50 test accuracy : 0.106\n",
      "50 test loss     : 2.289466181853506\n",
      "60 test accuracy : 0.118\n",
      "60 test loss     : 2.28706429447039\n",
      "70 test accuracy : 0.113\n",
      "70 test loss     : 2.28527969831296\n",
      "80 test accuracy : 0.124\n",
      "80 test loss     : 2.2842136678148255\n",
      "90 test accuracy : 0.124\n",
      "90 test loss     : 2.281113821307411\n",
      "100 test accuracy : 0.114\n",
      "100 test loss     : 2.2782839750817456\n",
      "110 test accuracy : 0.115\n",
      "110 test loss     : 2.276396747608512\n",
      "120 test accuracy : 0.115\n",
      "120 test loss     : 2.274919342372417\n",
      "130 test accuracy : 0.12\n",
      "130 test loss     : 2.273068137058073\n",
      "140 test accuracy : 0.116\n",
      "140 test loss     : 2.270944120903973\n",
      "150 test accuracy : 0.117\n",
      "150 test loss     : 2.2695444727390233\n",
      "160 test accuracy : 0.108\n",
      "160 test loss     : 2.267781007378231\n",
      "170 test accuracy : 0.119\n",
      "170 test loss     : 2.2650531394318714\n",
      "180 test accuracy : 0.119\n",
      "180 test loss     : 2.263119117836669\n",
      "190 test accuracy : 0.118\n",
      "190 test loss     : 2.261565920687666\n",
      "200 test accuracy : 0.125\n",
      "200 test loss     : 2.25944579356263\n",
      "210 test accuracy : 0.127\n",
      "210 test loss     : 2.2581324243720315\n",
      "220 test accuracy : 0.121\n",
      "220 test loss     : 2.255200796418638\n",
      "230 test accuracy : 0.126\n",
      "230 test loss     : 2.25179479564171\n",
      "240 test accuracy : 0.123\n",
      "240 test loss     : 2.24878494132973\n",
      "250 test accuracy : 0.127\n",
      "250 test loss     : 2.2427603642304184\n",
      "260 test accuracy : 0.131\n",
      "260 test loss     : 2.2352006053628\n",
      "270 test accuracy : 0.138\n",
      "270 test loss     : 2.2256349477759607\n",
      "280 test accuracy : 0.148\n",
      "280 test loss     : 2.20994200706036\n",
      "290 test accuracy : 0.157\n",
      "290 test loss     : 2.1916765195747203\n",
      "300 test accuracy : 0.162\n",
      "300 test loss     : 2.1701989738367358\n",
      "310 test accuracy : 0.166\n",
      "310 test loss     : 2.14882782212435\n",
      "320 test accuracy : 0.169\n",
      "320 test loss     : 2.1300193089330004\n",
      "330 test accuracy : 0.172\n",
      "330 test loss     : 2.1141567345364476\n",
      "340 test accuracy : 0.177\n",
      "340 test loss     : 2.102151854054939\n",
      "350 test accuracy : 0.194\n",
      "350 test loss     : 2.0933854499474744\n",
      "360 test accuracy : 0.2\n",
      "360 test loss     : 2.0871768591671556\n",
      "370 test accuracy : 0.207\n",
      "370 test loss     : 2.081441924472191\n",
      "380 test accuracy : 0.211\n",
      "380 test loss     : 2.0759368527481414\n",
      "390 test accuracy : 0.216\n",
      "390 test loss     : 2.071213430842053\n",
      "400 test accuracy : 0.224\n",
      "400 test loss     : 2.0664593566330045\n",
      "410 test accuracy : 0.219\n",
      "410 test loss     : 2.0618693831213153\n",
      "420 test accuracy : 0.225\n",
      "420 test loss     : 2.0571944575370136\n",
      "430 test accuracy : 0.222\n",
      "430 test loss     : 2.0524927119917358\n",
      "440 test accuracy : 0.227\n",
      "440 test loss     : 2.048213348051635\n",
      "450 test accuracy : 0.224\n",
      "450 test loss     : 2.0423594486671055\n",
      "460 test accuracy : 0.22\n",
      "460 test loss     : 2.0391238880960256\n",
      "470 test accuracy : 0.235\n",
      "470 test loss     : 2.0309583489806253\n",
      "480 test accuracy : 0.224\n",
      "480 test loss     : 2.02668734954347\n",
      "490 test accuracy : 0.233\n",
      "490 test loss     : 2.0212261235001727\n",
      "500 test accuracy : 0.238\n",
      "500 test loss     : 2.016199499713498\n",
      "510 test accuracy : 0.242\n",
      "510 test loss     : 2.0098037600571788\n",
      "520 test accuracy : 0.259\n",
      "520 test loss     : 2.0032857818751353\n",
      "530 test accuracy : 0.262\n",
      "530 test loss     : 1.9987492380389886\n",
      "540 test accuracy : 0.257\n",
      "540 test loss     : 1.9938525838455126\n",
      "550 test accuracy : 0.268\n",
      "550 test loss     : 1.9871092086442348\n"
     ]
    }
   ],
   "source": [
    "history = {'val_acc': [],'val_loss': []} #기록해서 그림 그리자!\n",
    "\n",
    "#코드를 보며 epoch, batch에 대해서 이해해봅시다.\n",
    "for i in range(epoch_size):\n",
    "    for j in range(N//batch_size):\n",
    "        batch_mask = np.random.choice(N, batch_size) #이번 배치에서 쓸 데이터들 인덱스 추출\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = y_train[batch_mask]\n",
    "        \n",
    "        nn.backward(x_batch, t_batch, learning_rate) # 가중치 갱신\n",
    "    \n",
    "    #accuracy와 loss를 기록해둡시다.\n",
    "    history[\"val_acc\"].append(nn.accuracy(x_test, y_test))\n",
    "    history[\"val_loss\"].append(nn.forward(x_test, y_test))\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i, \"test accuracy :\", nn.accuracy(x_test, y_test))\n",
    "        print(i, \"test loss     :\", nn.forward(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax_acc = fig.add_subplot(111)\n",
    "\n",
    "ax_acc.plot(range(epoch_size), history['val_acc'], label='정확도(%)', color='darkred')\n",
    "#plt.text(3, 14.7, \"<----------------정확도(%)\", verticalalignment='top', horizontalalignment='right')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Validation Accuracy(%)')\n",
    "ax_acc.grid(linestyle='--', color='lavender')\n",
    "ax_loss = ax_acc.twinx()\n",
    "ax_loss.plot(range(epoch_size), history['val_loss'], label='오차', color='darkblue')\n",
    "#plt.text(3, 2.2, \"<----------------오차\", verticalalignment='top', horizontalalignment='left')\n",
    "plt.ylabel('Validation Error')\n",
    "ax_loss.yaxis.tick_right()\n",
    "ax_loss.grid(linestyle='--', color='lavender')\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()\n",
    "\n",
    "# 나의 최고 validation accuracy는? 두구두구~\n",
    "print(\"나의 최고 validation loss : \", max(history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
